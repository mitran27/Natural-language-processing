# Natural-language-processing
build simple nlp models with/without deep learning libraries

<h2> 1) Tokenization</h2>

<ul>
  <li>text cleaning</li>
  <li>regex</li>
  <li>stemming</li>
  <li>lemmatization</li>
</ul>


<h2> 2) Feature extraction</h2>
Extracting important  features from text
<ul>
  <li>Bag of words</li>
  <li>TF-IDF</li>
  <li>n-gram</li>
  <li>one ot encoding</li>
</ul>


<h2> 2) Feature extraction</h2>
Extracting important  features from text
<ul>
  <li>Bag of words</li>
  <li>TF-IDF</li>
  <li>n-gram</li>
  <li>one ot encoding</li>
</ul>



<h2> 3) Mini projects</h2>
Building small Nlp projects using nltk library and some algorithms
<ul>
  <li>Pos tegginh</li>
  <li>summarization using histogram </li>
  <li>summarization using pagerank </li>
  <li>topic modelling</li>
</ul>


<h2> 4) Embedding</h2>
representing sematic meaning of a word in terms of mathematical form(real valued vector)
<ul>
  <li>word 2 vec</li>
  <li>skipgram </li>
  <li>glove </li>
</ul>

<h2> 4) ML projects</h2>
building nlp using machine learning algorithms
<ul>
  <li>Naive bayes</li>
  <li>logistic regression </li>
</ul>

<h2> 4) DL projects</h2>
building nlp using depp learning algorithms
<ul>
  <li>CNN</li>
  <li>RNN </li>
  <li>GRU</li>
  <li>LSTM </li>
  <li>biLSTM</li>
  <li>stacked lstm </li>
</ul>

<h2> 4) seq 2 seq projects</h2>
building sequence to sequence projects using encoder and decoder
<ul>
  <li>seq2seq</li>
  <li>seq2seq with attention </li>
  
</ul>











